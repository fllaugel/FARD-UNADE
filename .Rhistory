maxf <- exp(8*10) # valor maximo de la funcion
Area <- function(f, xmin = 5, xmax = 10, ymin = 0, ymax = maxf, n = 10000) {
x <- runif(n, xmin, xmax)
y <- runif(n, ymin, ymax)
sum(y < f(x))/n* (xmax - xmin) * (ymax - ymin) # proporcion de los puntos debajo de la curva
}
f <- function(x){
exp(8*x)
}
Area(f)
#	3. Genere y grafique 10,000 números aleatorios con la ecuación: y_i=(2^31 y_(i-1)+2^15 )modulo 2^20
y[1] <- 7823
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
y[1] <- 7823
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
y <-rep(10000,0)
y[1] <- 7823
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
hist(y)
y[1] <- 7919
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
hist(y)
y <-rep(10000,0)
y[1] <- 53982894593057
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
hist(y)
str(y)
summary(y)
hist(y, breaks = 20)
hist(y, breaks = 200)
hist(y, breaks = 5)
yy <-y[3:10000]
hist(yy)
hist(yy)
summary(yy)
summary(y)
y <-rep(10000,0)
y[1] <-  2428095424619
for( i in 2:10000){
y[i] <- (2^31*y[i-1] + 2^15)%%2^20
}
hist(y, breaks = 5)
summary(y)
num <- rnorm(1000,10,2)
hist(num)
curve(dnorm(num), lty = 1, lwd = 2, add = TRUE)
curve(dnorm(rnorm(1000,10,2)), lty = 1, lwd = 2, add = TRUE)
dnorm(num)
curve(dnorm(num))
curve(num)
plot(num)
plot(num,dnorm(num))
plot(num,dnorm(num) type="l")
plot(num,dnorm(num) ,type="l")
library(plyr)
knitr::opts_chunk$set(echo = TRUE)
docentes <- read.csv("docentes.csv", sep = ",",header = T, dec = ".",
comment.char = "", strip.white = TRUE,
stringsAsFactors = TRUE, encoding="latin1")
# lee dataset de alumnos con caracteres en espanol
alumnos <- read.csv("alumnos.csv", sep = ",",header = T, dec = ".",
comment.char = "", strip.white = TRUE,
stringsAsFactors = TRUE, encoding="latin1")
# descripcion de datos
str(docentes)
str(alumnos)
respalumnos <- subset(alumnos, select= -c(AP0,AP10)) # seleccciona respuestas categoricas
respdocentes <- subset(docentes, select= -c(DP1,DP3,DP12)) # seleccciona respuestas categoricas
questions <- respalumnos
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
library(dplyr)
library(tidyr)
library(ggplot2) # para graficos
library(scales)  # para calcular los porcentajes
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
View(questions)
questions <- respalumnos
View(questions)
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
# carga paquetes requeridos
library(tidyverse)
library(hrbrthemes)
library(cluster)
library(NbClust)
library(factoextra)
# funcion para analisis de conglomerados
gruposs <- 0
gruposnum <- NULL
grupos <- function(datos, tipo){
domains.dist <- daisy(datos,metric="gower") # calcula matriz de falta de similitud
# k-medoids clustering or partitioning around medoids (PAM)
# visualiza la matriz, Values of 1 are completely dissimilar and values of 0 means identical responses
# steelblue
gradient.color <- list(low = "steelblue",  high = "white")
fviz_dist(domains.dist,
gradient = gradient.color,order=F, show_labels = T,   lab_size = 4)
# determina el numero de clusters usando el metodo de siluetas
number_clusters <- NbClust(diss=domains.dist,distance=NULL,
min.nc = 2, max.nc = 10,
method = "median",
index="silhouette")
gruposs <<- number_clusters
# visualiza los clusters , 2 por que fue resultado de numero de clusters
# usa la grafica del metodo Classical (Metric) Multidimensional Scaling (NDS)
domains.pam <- pam(domains.dist,2)
titulo <- paste("Gráfica MDS de respuestas de ",tipo)
respuestas.mds <- as.data.frame(cmdscale(domains.dist,2))
respuestas.mds$respuestas_cluster <- as.factor(domains.pam$clustering)
ggplot(respuestas.mds,aes(x=V1,y=V2,color=respuestas_cluster)) +
geom_point() + theme_ipsum() +
labs(title=titulo,
subtitle="Coloreado por grupo PAM") +
scale_color_brewer(palette="Set1")
gruposnum <<- domains.pam$clustering  # muestra los miembros de cada grupo
}
# Calcula clusters para alumnos
grupos(respalumnos,"Alumnos")
gruposs
df <- as.data.frame(gruposnum) # convierte a data frame
GRUPO <- df$gruposnum
respalumnos <- cbind(respalumnos,GRUPO) # agrega numero de cluster
# Calcula clusters para docentes
grupos(respdocentes,"Docentes")
gruposs
df <- as.data.frame(gruposnum) # convierte a data frame
GRUPO <- df$gruposnum
respdocentes <- cbind(respdocentes,GRUPO) # agrega numero de cluster
View(respalumnos)
questions <- respalumnos
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
questions <- questions %>% gather(key='Pregunta', value='Respuesta',GRUPO)
questions <- questions %>% gather(GRUPO, key='Pregunta', value='Respuesta')
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
questions <- respalumnos
questions <- questions %>% gather(key='Pregunta', value='Respuesta')
questions <- respalumnos[,GRUPO=1]
View(respalumnos)
questions <- respalumnos[,GRUPO==1]
respalumnos[,1]
respalumnos[,GRUPO=1]
respalumnos[,"GRUPO"]
respalumnos[GRUPO=1]
respalumnos[GRUPO=1,]
respalumnos[respalumnos$GRUPO=1]
respalumnos[respalumnos$GRUPO=1,]
respalumnos[respalumnos$GRUPO<2,]
questions <- subset(questions, select=-GRUPO)
questions <- respalumnos[respalumnos$GRUPO<2,]
questions <- subset(questions, select=-GRUPO)
View(questions)
table(respalumnos$GRUPO)
table(respdocentes$GRUPO)
# CHUNK 1
library(igraph)
g <- graph_from_literal(1-2, 1-3, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 6-7)
# CHUNK 2
V(g)
# CHUNK 3
E(g)
# CHUNK 4
print_all(g)
# CHUNK 5
plot(g)
# CHUNK 6
dg <- graph_from_literal(1-+2, 1-+3, 2++3)
plot(dg)
# CHUNK 7
dg <- graph_from_literal(Sam-+Mary, Sam-+Tom,
Mary++Tom)
print_all(dg)
# CHUNK 8
V(dg)$name <- c("Sam", "Mary", "Tom")
plot(dgamma())
plot(dg)
# CHUNK 9
E(dg)
# CHUNK 10
as_adjacency_matrix(g)
# CHUNK 11
h <- induced_subgraph(g, 1:5)
print_all(h)
# CHUNK 12
h <- g - vertices(c(6,7))
# CHUNK 11
h <- induced_subgraph(g, 1:5)
plot(h)
# CHUNK 12
h <- g - vertices(c(6,7))
plot(h)
# CHUNK 13
h <- h + vertices(c(6,7))
plot(h)
g <- h + edges(c(4,6),c(4,7),c(5,6),c(6,7))
plot(g)
# CHUNK 14
h1 <- h
plot(h)
h2 <- graph_from_literal(4-6, 4-7, 5-6, 6-7)
plot(h2)
g <- union(h1,h2)
plot(g)
# CHUNK 15
V(dg)$name
# CHUNK 16
V(dg)$gender <- c("M","F","M")
# CHUNK 17
V(g)$color <- "red"
# CHUNK 18
is_weighted(g)
# ---
## [1] FALSE
# ---
wg <- g
plot(wg)
E(wg)$weight <- runif(ecount(wg))
is_weighted(wg)
plot(wg)
# CHUNK 19
g$name <- "Toy Graph"
plot(g)
# CHUNK 20
library(sand)
g.lazega <- graph_from_data_frame(elist.lazega,
directed="FALSE",
vertices=v.attr.lazega)
plot(g.lazega)
g.lazega$name <- "Lazega Lawyers"
# CHUNK 21
vcount(g.lazega)
# CHUNK 22
ecount(g.lazega)
# CHUNK 23
vertex_attr_names(g.lazega)
# CHUNK 24
is_simple(g)
# CHUNK 25
mg <- g + edge(2,3)
plot(mg)
print_all(mg)
## + attr: name (g/c), name (v/c), color (v/c)
## + edges (vertex names):
## 1 -- 2, 3
## 2 -- 1, 3, 3, 4
## 3 -- 1, 2, 2, 5
## 4 -- 2, 5, 6, 7
## 5 -- 3, 4, 6
## 6 -- 4, 5, 7
## 7 -- 4, 6
# ---
is_simple(mg)
# CHUNK 26
E(mg)$weight <- 1
wg2 <- simplify(mg)
plot(mg)
plot(wg2)
# CHUNK 27
print_all(wg2)
# CHUNK 28
E(wg2)$weight
# CHUNK 29
neighbors(g,5)
# CHUNK 30
degree(g)
# CHUNK 31
degree(dg, mode="in")
plot(dg)
# CHUNK 31
degree(dg, mode="in")
# ---
##  Sam Mary  Tom
##    0    2    2
# ---
degree(dg, mode="out")
# CHUNK 32
is_connected(g)
# CHUNK 33
clusters(g)
plot(g)
# CHUNK 34
is_connected(dg,mode="weak")
# CHUNK 35
diameter(g, weights=NA)
plot(g)
# CHUNK 36
g.full <- make_full_graph(7)
plot(g.full)
g.ring <- make_ring(7)
g.tree <- make_tree(7, children=2, mode="undirected")
g.star <- make_star(7, mode="undirected")
par(mfrow=c(2, 2), mai = c(0.2, 0.2, 0.2, 0.2))
plot(g.full)
plot(g.ring)
plot(g.tree)
plot(g.star)
# CHUNK 37
is_dag(dg)
plot(dg)
# CHUNK 38
g.bip <- graph_from_literal(actor1:actor2:actor3,
movie1:movie2, actor1:actor2 - movie1,
actor2:actor3 - movie2)
plot(g.bip)
V(g.bip)$type <- grepl("^movie", V(g.bip)$name)
print_all(g.bip, v=T)
# CHUNK 39
proj <- bipartite_projection(g.bip)
proj
print_all(proj[[1]])
# ---
## IGRAPH 3782b1c UNW- 3 2 --
## + attr: name (v/c), weight (e/n)
## + edges from 3782b1c (vertex names):
## [1] actor1--actor2 actor2--actor3
# ---
print_all(proj[[2]])
# CHUNK 1
library(sand)
g.l <- make_lattice(c(5, 5, 5))
# CHUNK 2
data(aidsblog)
summary(aidsblog)
# CHUNK 3
igraph_options(vertex.size=3, vertex.label=NA,
edge.arrow.size=0.5)
par(mfrow=c(1, 2))
plot(g.l, layout=layout_in_circle)
title("5x5x5 Lattice")
plot(aidsblog, layout=layout_in_circle)
title("Blog Network")
# CHUNK 4
plot(g.l,layout=layout_with_fr)
title("5x5x5 Lattice")
plot(aidsblog,layout=layout_with_fr)
title("Blog Network")
# CHUNK 5
plot(g.l, layout=layout_with_kk)
title("5x5x5 Lattice")
plot(aidsblog, layout=layout_with_kk)
title("Blog Network")
# CHUNK 6
g.tree <- graph_from_literal(1-+2,1-+3,1-+4,2-+5,2-+6,
2-+7,3-+8,3-+9,4-+10)
par(mfrow=c(1, 3))
igraph_options(vertex.size=30, edge.arrow.size=0.5,
vertex.label=NULL)
plot(g.tree, layout=layout_in_circle)
plot(g.tree, layout=layout_as_tree(g.tree, circular=T))
plot(g.tree, layout=layout_as_tree)
# CHUNK 7
plot(g.bip, layout= -layout_as_bipartite(g.bip)[,2:1],
vertex.size=60, vertex.shape=ifelse(V(g.bip)$type,
"rectangle", "circle"),
vertex.label.cex=1.75,
vertex.color=ifelse(V(g.bip)$type, "red", "cyan"))
# CHUNK 8
library(igraphdata)
data(karate)
# Reproducible layout
set.seed(42)
l <- layout_with_kk(karate)
# Plot undecorated first.
igraph_options(vertex.size=10)
par(mfrow=c(1,1))
plot(karate, layout=l, vertex.label=V(karate),
vertex.color=NA)
# Now decorate, starting with labels.
V(karate)$label <- sub("Actor ", "", V(karate)$name)
# Two leaders get shapes different from club members.
V(karate)$shape <- "circle"
V(karate)[c("Mr Hi", "John A")]$shape <- "rectangle"
# Differentiate two factions by color.
V(karate)[Faction == 1]$color <- "red"
V(karate)[Faction == 2]$color <- "dodgerblue"
# Vertex area proportional to vertex strength
# (i.e., total weight of incident edges).
V(karate)$size <- 4*sqrt(strength(karate))
V(karate)$size2 <- V(karate)$size * .5
# Weight edges by number of common activities
E(karate)$width <- E(karate)$weight
# Color edges by within/between faction.
F1 <- V(karate)[Faction==1]
F2 <- V(karate)[Faction==2]
E(karate)[ F1 %--% F1 ]$color <- "pink"
E(karate)[ F2 %--% F2 ]$color <- "lightblue"
E(karate)[ F1 %--% F2 ]$color <- "yellow"
# Offset vertex labels for smaller points (default=0).
V(karate)$label.dist <-
ifelse(V(karate)$size >= 9.0, 0, 1.0)
# Plot decorated graph, using same layout.
plot(karate, layout=l)
# CHUNK 9
library(sand)
data(lazega)
# Office location indicated by color.
colbar <- c("red", "dodgerblue", "goldenrod")
v.colors <- colbar[V(lazega)$Office]
# Type of practice indicated by vertex shape.
v.shapes <- c("circle", "square")[V(lazega)$Practice]
# Vertex size proportional to years with firm.
v.size <- 3.5*sqrt(V(lazega)$Years)
# Label vertices according to seniority.
v.label <- V(lazega)$Seniority
# Reproducible layout.
set.seed(42)
l <- layout_with_fr(lazega)
plot(lazega, layout=l, vertex.color=v.colors,
vertex.shape=v.shapes, vertex.size=v.size,
vertex.label=v.label)
# CHUNK 10
library(sand)
summary(fblog)
# CHUNK 11
party.names <- sort(unique(V(fblog)$PolParty))
party.names
# CHUNK 12
set.seed(42)
l = layout_with_kk(fblog)
party.nums.f <- as.factor(V(fblog)$PolParty)
party.nums <- as.numeric(party.nums.f)
# igraph color palette has 8 colors
# 9 colors needed (for 9 political parties)
library(RColorBrewer)
colrs <- brewer.pal(9,"Set1")
V(fblog)$color <- colrs[party.nums]
plot(fblog, layout=l, vertex.label=NA,
vertex.size=3)
print(fblog)
l <- layout_with_drl(fblog)
plot(fblog, layout=l, vertex.size=5, vertex.label=NA)
# CHUNK 14
fblog.c <- contract(fblog, party.nums)
E(fblog.c)$weight <- 1
fblog.c <- simplify(fblog.c)
# CHUNK 15
party.size <- as.vector(table(V(fblog)$PolParty))
plot(fblog.c, vertex.size=5*sqrt(party.size),
vertex.label=party.names, vertex.color=colrs,
edge.width=sqrt(E(fblog.c)$weight),
vertex.label.dist=3.5, edge.arrow.size=0)
# CHUNK 16
data(karate)
k.nbhds <- make_ego_graph(karate, order=1)
# CHUNK 17
sapply(k.nbhds, vcount)
# CHUNK 18
k.1 <- k.nbhds[[1]]
k.34 <- k.nbhds[[34]]
par(mfrow=c(1,2))
plot(k.1, vertex.label=NA,
vertex.color=c("red", rep("lightblue", 16)))
plot(k.34, vertex.label=NA,
vertex.color=c(rep("lightblue", 17), "red"))
setwd("C:/SURFACEDATA/INSUDE/ASESORIA 2024/IMPACTO DE LA IA/PAPER IA/FARD-IA")
knitr::opts_chunk$set(echo = TRUE)
docentes <- read.csv("docentes.csv", sep = ",",header = T, dec = ".",
comment.char = "", strip.white = TRUE,
stringsAsFactors = TRUE, encoding="latin1")
# lee dataset de alumnos con caracteres en espanol
alumnos <- read.csv("alumnos.csv", sep = ",",header = T, dec = ".",
comment.char = "", strip.white = TRUE,
stringsAsFactors = TRUE, encoding="latin1")
View(docentes)
respalumnos <- subset(alumnos, select= -c(AP0,AP10)) # seleccciona respuestas categoricas
respdocentes <- subset(docentes, select= -c(DP1,DP3,DP12)) # seleccciona respuestas categoricas
View(respdocentes)
str(respalumnos)
tabla <- xtabs ( formula = count ~ DP5 + DP6 , data = respalumnos )
tabla <- xtabs ( formula = DP5 + DP6 , data = respalumnos )
tabla <- xtabs ( formula = DP5 + DP6 , data = respalumnos )
tabla <- xtabs ( formula = DP5 + DP6 , data = respdocentes )
tabla <- xtabs ( formula = DP5 + DP6 , data = respdocentes )
data(respdocentes)
tabla <- xtabs ( formula = respdocentes$DP5 + respdocentes$DP6 , data = respdocentes )
tabla <- xtabs ( ~respdocentes$DP5 + respdocentes$DP6 , data = respdocentes )
tabla
tabla <- xtabs ( ~DP5 + DP6 , data = respdocentes )
tabla <- xtabs ( ~ DP6 + DP9 , data = respdocentes )
tabla
tabla <- xtabs ( ~ DP7 + DP8 , data = respdocentes ) # construye tabla de contingencia
tabla
tabla2 <- xtabs ( ~ DP4 + DP5 , data = respdocentes ) # construye tabla de contingencia
tabla2
tabla3 <- xtabs ( ~ DP4 + DP6 , data = respdocentes ) # construye tabla de contingencia
tabla3
tabla3 <- xtabs ( ~ DP4 + DP11 , data = respdocentes ) # construye tabla de contingencia
tabla3
chisq.test(DP4,DP11, data=respdocentes)
chisq.test(respdocentes$DP4,respdocentes$DP11, correcy=F)
chisq.test(respdocentes$DP4,respdocentes$DP11, correct=F)
data(respdocentes)
attach(respdocentes)
chisq.test(DP4,DP11, correct=F)
chisq.test(DP7,DP8, correct=F)
chisq.test(DP4,DP5, correct=F)
chisq.test(DP4,DP6, correct=F)
chisq.test(DP4,DP11, correct=T)
chisq.test(DP4,DP11, correct=F)
tabla4 <- prop.table(xtabs ( ~ DP4 + DP11 , data = respdocentes )) # construye tabla de contingencia
tabla4
tabla4 <- prop.table(xtabs ( ~ DP4 + DP11 , data = respdocentes ))*100 # construye tabla de contingencia
tabla4
